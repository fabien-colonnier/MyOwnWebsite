.. title: Research
.. slug: research
.. date: 2019-05-03 15:13:00 UTC+08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text



My research interest is mainly focused on visual navigation for robotic application. I used bio-inspired method to solve robotic tasks such as stabilization, pursuit and obstacle avoidance.

<h2> Event-based visual sensor </h2>

A nice description of how the sensor work can be found <a href="https://youtu.be/LauQ6LWTkxM"> here </a> <br />

<ul>
<li>
<p>The Davis240C sensor was used to compute Optic Flow and perform obstacle avoidance with a quadrotor. <br /> </p>

<video width="560" height="315" controls preload="none" frameborder="0">
   <source src="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4" type="video/mp4">
   Your browser does not support the video tag.
</video>

</li>
</ul>
<!--
<iframe width="560" height="315" src="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4" preload="none" type="video/mp4" allowfullscreen></iframe>

<!--<a href="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4"> video</a> -->


<h2> Insect inspired vision and application </h2>

The following research was made during my PhD in the Biorobotics team in Marseille. My thesis can be downloaded here: <a href="/files/These_COLONNIER_Fabien.pdf"> Link to thesis</a> .

<ul>
<li>
Using an Artificial compound eye submitted to periodic micro-movements displays hyperacuity, <i>i.e.</i> locating features with a greater accuracy than that corresponding to the resolution imposed by the photoreceptorâ€™s limited pitch. Application of this principal over a large field of view allowed a robot to stabilized is position or follow a target.<br />
	<ul>
	<li>
	<p>Robotic visual stabilization and short-range odometry</p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/4_hqCgunhNw" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	</li>
	<li>
	<p>Robotic visual pursuit under different light conditions </p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/kdjJ6t7d2pM" frameborder="0" allow="accelerometer;  encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	<p> <br />which mimics the behavior of hoverfly trajectories</p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/fciQr0o0G7g" frameborder="0" allow="accelerometer;  encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	</li>
	</ul>
</li>
<br />

<li> <p>Collaboration on the robot LORA, which aims at replicating bees navigation into a large corridor. The different behaviors such as centering, wall-following and speed regulation in a tappered corridor were reproduced using Optic Flow measurements. <br /> </p>

<iframe frameborder="0" width="560" height="315" src="https://www.dailymotion.com/embed/video/xuggrs" allowfullscreen allow=""></iframe>
</li>

</ul>






